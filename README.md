# Bias and Fairness in Large Language Models: A Survey
> Isabel O. Gallegos, Ryan A. Rossi, Joe Barrow, Md Mehrab Tanjim, Sungchul Kim, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, and Nesreen K. Ahmed

Pre-print: https://arxiv.org/abs/2309.00770

If you use or discuss our survey in your work, please use the following citation:
```
@article{gallegos2023bias,
    title={Bias and Fairness in Large Language Models: A Survey},
    author={Gallegos, Isabel O and Rossi, Ryan A and Barrow, Joe and Tanjim, Md Mehrab and Kim, Sungchul and Dernoncourt, Franck and Yu, Tong and Zhang, Ruiyi and Ahmed, Nesreen K},
    journal={arXiv preprint arXiv:2309.00770},
    year={2023}
}
```

To enable easy use of bias evaluation datasets, we compile publicly-available ones and provide access here. We provide links to the original data sources below. We do not modify any of the datasets, but do remove unrelated material from the original repositories. Please refer to the original works for more detailed documentation.

| Dataset                  | Link                                                                                       |
|--------------------------|--------------------------------------------------------------------------------------------|
| BBQ                      | https://github.com/nyu-mll/BBQ                                                             |
| BEC-Pro                  | https://github.com/marionbartl/gender-bias-BERT                                            |
| Bias NLI                 | https://github.com/sunipa/On-Measuring-and-Mitigating-Biased-Inferences-of-Word-Embeddings |
| BOLD                     | https://github.com/amazon-science/bold                                                     |
| BUG                      | https://github.com/SLAB-NLP/BUG                                                            |
| CrowS-Pairs              | https://github.com/nyu-mll/crows-pairs/                                                    |
| Equity Evaluation Corpus | http://saifmohammad.com/WebPages/Biases-SA.html                                            |
| GAP                      | https://github.com/google-research-datasets/gap-coreference                                |
| Grep-BiasIR              | https://github.com/KlaraKrieg/GrepBiasIR                                                   |
| HolisticBias             | https://github.com/facebookresearch/ResponsibleNLP                                         |
| HONEST                   | https://github.com/MilaNLProc/honest                                                       |
| PANDA                    | https://github.com/facebookresearch/ResponsibleNLP                                         |
| RealToxicityPrompts      | https://toxicdegeneration.allenai.org                                                      |
| RedditBias               | https://github.com/umanlp/RedditBias                                                       |
| StereoSet                | https://github.com/McGill-NLP/bias-bench, https://github.com/moinnadeem/stereoset          |
| TrustGPT                 | https://github.com/HowieHwong/TrustGPT                                                     |
| UnQover                  | https://github.com/allenai/unqover                                                         |
| WinoBias                 | https://github.com/uclanlp/corefBias                                                       |
| WinoBias+                | https://github.com/vnmssnhv/NeuTralRewriter                                                |
| WinoGender               | https://github.com/rudinger/winogender-schemas                                             |
| WinoQueer                | https://github.com/katyfelkner/winoqueer                                                   |
